{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":168},"id":"T3gFChwhJlLj","outputId":"05bce5b6-a24f-4a7c-c759-41752fbbb25f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: treeple in /usr/local/lib/python3.10/dist-packages (0.9.1)\n","Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from treeple) (1.26.4)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from treeple) (1.13.1)\n","Requirement already satisfied: scikit-learn>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from treeple) (1.5.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.1->treeple) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.1->treeple) (3.5.0)\n"]},{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-b9326ba4-2c7a-457d-af34-92145e52ac1b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b9326ba4-2c7a-457d-af34-92145e52ac1b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["!pip install treeple\n","from google.colab import files\n","uploaded = files.upload()\n","import sys\n","sys.path.append('/content')\n","import tree_metrics\n","from pathlib import Path\n","from treeple import PatchObliqueRandomForestClassifier\n","\n","import numpy as np\n","from joblib import Parallel, delayed\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from treeple import HonestForestClassifier\n","from treeple.datasets import (make_trunk_classification,\n","                              make_trunk_mixture_classification)\n","from treeple.stats import PermutationHonestForestClassifier, build_oob_forest\n","from treeple.stats.utils import _mutual_information\n","from treeple.tree import MultiViewDecisionTreeClassifier\n","from sklearn.metrics import roc_auc_score, roc_curve\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","# 创建 figures 文件夹，如果它不存在\n","os.makedirs('/content/figures', exist_ok=True)\n","plt.savefig('/content/figures/might_S@98.png')\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import tree_metrics\n","from print_importance import might_importance\n","\n","n_estimators = 1000\n","max_features = 0.3\n","MODEL_NAMES = {\n","    \"might\": {\n","        \"n_estimators\": n_estimators,\n","        \"honest_fraction\": 0.5,\n","        \"n_jobs\": 40,\n","        \"bootstrap\": True,\n","        \"stratify\": True,\n","        \"max_samples\": 0.6,\n","        \"max_features\": 0.3,\n","        \"tree_estimator\": MultiViewDecisionTreeClassifier(),\n","    },\"morf\": {\n","        \"n_estimators\": 100,\n","        \"max_patch_dims\": None,\n","        \"data_dims\": [2524],  # 根据您的数据维度进行调整\n","        \"n_jobs\": 40,\n","        \"bootstrap\": True,\n","        \"max_samples\": 0.6,\n","        \"max_features\": 0.3,\n","        \"random_state\": 42,\n","    },\n","}\n","might_kwargs = MODEL_NAMES[\"might\"]\n","sample_list_file = \"/content/AllSamples.MIGHT.Passed.samples.txt\"\n","sample_list = pd.read_csv(sample_list_file, sep=\" \", header=None)\n","sample_list.columns = [\"library\", \"sample_id\", \"cohort\"]\n","sample_list.head()\n","cohort2 = sample_list[sample_list[\"cohort\"] == \"Cohort2\"][\"sample_id\"]\n","print(len(cohort2))\n","PON = sample_list[sample_list[\"cohort\"] == \"PanelOfNormals\"][\"sample_id\"]\n","sample_list[\"cohort\"].unique()\n","def get_X_y(f, root=\"\", cohort=cohort2, verbose=False):\n","    df = pd.read_csv(root + f)\n","    non_features = ['Run', 'Library', 'Cancer Status', 'Tumor type', 'Stage', 'Library volume (uL)', 'Library Volume',\n","                    'UIDs Used', 'Experiment', 'P7', 'P7 Primer', 'MAF']\n","    sample_ids = df[\"Sample\"]\n","    for i, sample_id in enumerate(sample_ids):\n","        if \".\" in sample_id:\n","            # print(sample_id.split(\".\")[1])\n","            if \"Wise\" in f or 'ichorCNA' in f:\n","                sample_ids[i] = sample_id\n","            else:\n","                sample_ids[i] = sample_id.split(\".\")[1]\n","    target = 'Cancer Status'\n","    y = df[target]\n","    y = y.replace(\"Healthy\", 0)\n","    y = y.replace(\"Cancer\", 1)\n","    for col in non_features:\n","        if col in df.columns:\n","            df = df.drop(col, axis=1)\n","    nan_cols = df.isnull().all(axis=0).to_numpy()\n","    # drop the columns with all nan values\n","    df = df.loc[:, ~nan_cols]\n","    if cohort is not None:\n","        # filter the rows with cohort1 samples\n","        X = df[sample_ids.isin(cohort)]\n","        # print(X.shape)\n","        y = y[sample_ids.isin(cohort)]\n","    else:\n","        X = df\n","    if \"Wise\" in f:\n","      X = X.fillna(0)\n","    X.iloc[:, 1] = X.iloc[:, 1].fillna(X.iloc[:, 1].mean(axis=0))\n","    nan_cols = X.isnull().all(axis=0)\n","    X = X.loc[:, ~nan_cols]\n","    if verbose:\n","        if nan_cols.sum() > 0:\n","            print(f)\n","            print(f\"nan_cols: {nan_cols.sum()}\")\n","            print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n","        else:\n","            print(f)\n","            print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n","    return X, y\n","def stratified_train_ml(clf, X, y):\n","    n_samples = X.shape[0]\n","    cv = StratifiedKFold(n_splits=5, shuffle=True)\n","    POS = np.zeros((len(y), 3))\n","\n","    for idx, (train_ix, test_ix) in enumerate(cv.split(X, y)):\n","        X_train, X_test = X[train_ix, :], X[test_ix, :]\n","        y_train, y_test = y[train_ix], y[test_ix]\n","\n","        ### Split Training Set into Fitting Set (40%) and Calibarating Set (40%)\n","        train_idx = np.arange(\n","            X_train.shape[0]\n","        )  # use index array to split, so we can use the same index for the permuted array as well\n","        fit_idx, cal_idx = train_test_split(\n","            train_idx, test_size=0.5, random_state=idx, stratify=y_train\n","        )\n","        X_fit, X_cal, y_fit, y_cal = (\n","            X_train[fit_idx],\n","            X_train[cal_idx],\n","            y_train[fit_idx],\n","            y_train[cal_idx],\n","        )\n","\n","        POS[test_ix, 0] = y_test\n","        clf.fit(X_fit, y_fit)\n","        if X_cal.shape[0] <= 1000:\n","            calibrated_model = CalibratedClassifierCV(\n","                clf, cv=\"prefit\", method=\"sigmoid\"\n","            )\n","        else:\n","            calibrated_model = CalibratedClassifierCV(\n","                clf, cv=\"prefit\", method=\"isotonic\"\n","            )\n","        calibrated_model.fit(X_cal, y_cal)\n","        posterior = calibrated_model.predict_proba(X_test)\n","\n","        POS[test_ix, 1:] = posterior\n","    return clf, POS\n","\n","def run_alog(f1, cohort=cohort2, model_name='might'):\n","    X_1, y_1 = get_X_y('{}.csv'.format(f1), cohort=cohort2, verbose=True)\n","    X = X_1.iloc[:, 1:]\n","\n","    if model_name == 'might':\n","        est = HonestForestClassifier(**might_kwargs)\n","\n","    elif model_name == 'morf':\n","        est = PatchObliqueRandomForestClassifier(**MODEL_NAMES[model_name])\n","    else:\n","        raise ValueError(f\"Unknown model name: {model_name}\")\n","    X_combine = X.fillna(0)\n","\n","    if model_name in ['might', 'morf']:\n","        est, posterior_arr = build_oob_forest(est, X, y_1, verbose=False)\n","    else:\n","        est, posterior_arr = stratified_train_ml(est, np.array(X_combine), np.array(y_1))\n","\n","    if model_name in ['might', 'morf']:\n","        POS = np.nanmean(posterior_arr, axis=0)\n","    else:\n","        POS = posterior_arr\n","\n","\n","    print(\"POS shape:\", POS.shape)\n","    if POS.shape[1] >= 2:\n","        fpr, tpr, thresholds = roc_curve(y_1, POS[:, -1], pos_label=1, drop_intermediate=False)\n","    else:\n","        print(\"POS 的列数不足，无法计算 roc_curve\")\n","\n","    S98 = np.max(tpr[fpr <= 0.02])\n","    tree_metrics.plot_S98(S98, fpr, tpr, model_name)\n","\n","    MI = tree_metrics.Calculate_MI(model_name, y_1, POS)\n","    pAUC = tree_metrics.Calculate_pAUC(model_name, y_1, POS, fpr, tpr)\n","    hd = tree_metrics.Calculate_hd(model_name, POS)\n","\n","    might_importance(model_name, est, X_combine)\n","\n","    output_fname = f\"{model_name}.npz\"\n","    print(model_name, f1)\n","    print(model_name, S98, MI, pAUC, hd)\n","    np.savez_compressed(\n","        output_fname,\n","        model_name=model_name,\n","        y=y_1,\n","        S98=S98,\n","        posterior_arr=posterior_arr,\n","        MI=MI,\n","        pAUC=pAUC,\n","        hd=hd\n","    )\n","    return S98\n","\n","for i in range(20):\n","    Parallel(n_jobs=40)(\n","        delayed(run_alog)(f1='WiseCondorX.Wise-1', cohort=cohort2, model_name=modelname)\n","        for modelname in ['might', 'morf']\n","    )"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEWxW3rdRop/cO6Xo4hiDg"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}