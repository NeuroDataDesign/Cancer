{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e4211f-aad4-4eea-8c60-1adf4dcd6eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install treeple\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "import sys\n",
    "sys.path.append('/content')\n",
    "import tree_metrics\n",
    "from pathlib import Path\n",
    "from treeple import PatchObliqueRandomForestClassifier\n",
    "\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from treeple import HonestForestClassifier\n",
    "from treeple.datasets import (make_trunk_classification,\n",
    "                              make_trunk_mixture_classification)\n",
    "from treeple.stats import PermutationHonestForestClassifier, build_oob_forest\n",
    "from treeple.stats.utils import _mutual_information\n",
    "from treeple.tree import MultiViewDecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# 创建 figures 文件夹，如果它不存在\n",
    "os.makedirs('/content/figures', exist_ok=True)\n",
    "plt.savefig('/content/figures/might_S@98.png')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tree_metrics\n",
    "from print_importance import might_importance\n",
    "\n",
    "n_estimators = 1000\n",
    "max_features = 0.3\n",
    "MODEL_NAMES = {\n",
    "    \"might\": {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"honest_fraction\": 0.5,\n",
    "        \"n_jobs\": 40,\n",
    "        \"bootstrap\": True,\n",
    "        \"stratify\": True,\n",
    "        \"max_samples\": 0.6,\n",
    "        \"max_features\": 0.3,\n",
    "        \"tree_estimator\": MultiViewDecisionTreeClassifier(),\n",
    "    },\"morf\": {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_patch_dims\": None,\n",
    "        \"data_dims\": [2524],  # 根据您的数据维度进行调整\n",
    "        \"n_jobs\": 40,\n",
    "        \"bootstrap\": True,\n",
    "        \"max_samples\": 0.6,\n",
    "        \"max_features\": 0.3,\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "}\n",
    "might_kwargs = MODEL_NAMES[\"might\"]\n",
    "sample_list_file = \"/content/AllSamples.MIGHT.Passed.samples.txt\"\n",
    "sample_list = pd.read_csv(sample_list_file, sep=\" \", header=None)\n",
    "sample_list.columns = [\"library\", \"sample_id\", \"cohort\"]\n",
    "sample_list.head()\n",
    "cohort2 = sample_list[sample_list[\"cohort\"] == \"Cohort2\"][\"sample_id\"]\n",
    "print(len(cohort2))\n",
    "PON = sample_list[sample_list[\"cohort\"] == \"PanelOfNormals\"][\"sample_id\"]\n",
    "sample_list[\"cohort\"].unique()\n",
    "def get_X_y(f, root=\"\", cohort=cohort2, verbose=False):\n",
    "    df = pd.read_csv(root + f)\n",
    "    non_features = ['Run', 'Library', 'Cancer Status', 'Tumor type', 'Stage', 'Library volume (uL)', 'Library Volume',\n",
    "                    'UIDs Used', 'Experiment', 'P7', 'P7 Primer', 'MAF']\n",
    "    sample_ids = df[\"Sample\"]\n",
    "    for i, sample_id in enumerate(sample_ids):\n",
    "        if \".\" in sample_id:\n",
    "            # print(sample_id.split(\".\")[1])\n",
    "            if \"Wise\" in f or 'ichorCNA' in f:\n",
    "                sample_ids[i] = sample_id\n",
    "            else:\n",
    "                sample_ids[i] = sample_id.split(\".\")[1]\n",
    "    target = 'Cancer Status'\n",
    "    y = df[target]\n",
    "    y = y.replace(\"Healthy\", 0)\n",
    "    y = y.replace(\"Cancer\", 1)\n",
    "    for col in non_features:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(col, axis=1)\n",
    "    nan_cols = df.isnull().all(axis=0).to_numpy()\n",
    "    # drop the columns with all nan values\n",
    "    df = df.loc[:, ~nan_cols]\n",
    "    if cohort is not None:\n",
    "        # filter the rows with cohort1 samples\n",
    "        X = df[sample_ids.isin(cohort)]\n",
    "        # print(X.shape)\n",
    "        y = y[sample_ids.isin(cohort)]\n",
    "    else:\n",
    "        X = df\n",
    "    if \"Wise\" in f:\n",
    "      X = X.fillna(0)\n",
    "    X.iloc[:, 1] = X.iloc[:, 1].fillna(X.iloc[:, 1].mean(axis=0))\n",
    "    nan_cols = X.isnull().all(axis=0)\n",
    "    X = X.loc[:, ~nan_cols]\n",
    "    if verbose:\n",
    "        if nan_cols.sum() > 0:\n",
    "            print(f)\n",
    "            print(f\"nan_cols: {nan_cols.sum()}\")\n",
    "            print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "        else:\n",
    "            print(f)\n",
    "            print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    return X, y\n",
    "def stratified_train_ml(clf, X, y):\n",
    "    n_samples = X.shape[0]\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    POS = np.zeros((len(y), 3))\n",
    "\n",
    "    for idx, (train_ix, test_ix) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "\n",
    "        ### Split Training Set into Fitting Set (40%) and Calibarating Set (40%)\n",
    "        train_idx = np.arange(\n",
    "            X_train.shape[0]\n",
    "        )  # use index array to split, so we can use the same index for the permuted array as well\n",
    "        fit_idx, cal_idx = train_test_split(\n",
    "            train_idx, test_size=0.5, random_state=idx, stratify=y_train\n",
    "        )\n",
    "        X_fit, X_cal, y_fit, y_cal = (\n",
    "            X_train[fit_idx],\n",
    "            X_train[cal_idx],\n",
    "            y_train[fit_idx],\n",
    "            y_train[cal_idx],\n",
    "        )\n",
    "\n",
    "        POS[test_ix, 0] = y_test\n",
    "        clf.fit(X_fit, y_fit)\n",
    "        if X_cal.shape[0] <= 1000:\n",
    "            calibrated_model = CalibratedClassifierCV(\n",
    "                clf, cv=\"prefit\", method=\"sigmoid\"\n",
    "            )\n",
    "        else:\n",
    "            calibrated_model = CalibratedClassifierCV(\n",
    "                clf, cv=\"prefit\", method=\"isotonic\"\n",
    "            )\n",
    "        calibrated_model.fit(X_cal, y_cal)\n",
    "        posterior = calibrated_model.predict_proba(X_test)\n",
    "\n",
    "        POS[test_ix, 1:] = posterior\n",
    "    return clf, POS\n",
    "\n",
    "def run_alog(f1, cohort=cohort2, model_name='might'):\n",
    "    X_1, y_1 = get_X_y('{}.csv'.format(f1), cohort=cohort2, verbose=True)\n",
    "    X = X_1.iloc[:, 1:]\n",
    "\n",
    "    if model_name == 'might':\n",
    "        est = HonestForestClassifier(**might_kwargs)\n",
    "\n",
    "    elif model_name == 'morf':\n",
    "        est = PatchObliqueRandomForestClassifier(**MODEL_NAMES[model_name])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    X_combine = X.fillna(0)\n",
    "\n",
    "    if model_name in ['might', 'morf']:\n",
    "        est, posterior_arr = build_oob_forest(est, X, y_1, verbose=False)\n",
    "    else:\n",
    "        est, posterior_arr = stratified_train_ml(est, np.array(X_combine), np.array(y_1))\n",
    "\n",
    "    if model_name in ['might', 'morf']:\n",
    "        POS = np.nanmean(posterior_arr, axis=0)\n",
    "    else:\n",
    "        POS = posterior_arr\n",
    "\n",
    "\n",
    "    print(\"POS shape:\", POS.shape)\n",
    "    if POS.shape[1] >= 2:\n",
    "        fpr, tpr, thresholds = roc_curve(y_1, POS[:, -1], pos_label=1, drop_intermediate=False)\n",
    "    else:\n",
    "        print(\"POS 的列数不足，无法计算 roc_curve\")\n",
    "\n",
    "    S98 = np.max(tpr[fpr <= 0.02])\n",
    "    tree_metrics.plot_S98(S98, fpr, tpr, model_name)\n",
    "\n",
    "    MI = tree_metrics.Calculate_MI(model_name, y_1, POS)\n",
    "    pAUC = tree_metrics.Calculate_pAUC(model_name, y_1, POS, fpr, tpr)\n",
    "    hd = tree_metrics.Calculate_hd(model_name, POS)\n",
    "\n",
    "    might_importance(model_name, est, X_combine)\n",
    "\n",
    "    output_fname = f\"{model_name}.npz\"\n",
    "    print(model_name, f1)\n",
    "    print(model_name, S98, MI, pAUC, hd)\n",
    "    np.savez_compressed(\n",
    "        output_fname,\n",
    "        model_name=model_name,\n",
    "        y=y_1,\n",
    "        S98=S98,\n",
    "        posterior_arr=posterior_arr,\n",
    "        MI=MI,\n",
    "        pAUC=pAUC,\n",
    "        hd=hd\n",
    "    )\n",
    "    return S98\n",
    "\n",
    "for i in range(20):\n",
    "    Parallel(n_jobs=40)(\n",
    "        delayed(run_alog)(f1='WiseCondorX.Wise-1', cohort=cohort2, model_name=modelname)\n",
    "        for modelname in ['might', 'morf']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
